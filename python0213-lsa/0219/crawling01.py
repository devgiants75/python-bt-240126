### 웹 크롤링 (crawling) ###

#! 1. 웹 크롤링 (web crawling)
# : 웹 페이지를 체계적으로 탐색하여 원하는 데이터를 추출하는 행위
# : 웹 크롤러(스파이더, 로봇) - 크롤링 수행 프로그램을 사용

#! 2. 웹 크롤링의 목적
# a. 검색 엔진 최적화(SEO)
# : 웹 크롤러는 웹 페이지의 내용을 인덱싱(추출)하기 위해 사용
# : 검색 엔진이 사용자에게 보다 관련성 높은 검색 결과를 제공

# b. 데이터 수집
# : 특정 웹 사이트에서 정보를 수집할 경우 사용
# : 시장 조사, 뉴스 기사의 데이터, 경쟁사 모니터링 등

#! 3. 파이썬을 이용한 웹 크롤링
# : 파이썬 외부 라이브러리 사용 (BeautifulSoup, Scrapy 등)
# : 확장성이 높음 - 다양한 데이터 처리 및 분석 도구와 연동이 용이
#   > 데이터 분석, 시각화 등의 후속 처리에 용이

### HTTP의 기본 이해 ###

#! HTTP (HyperText Trasfer Protocol의 약자)
# : 웹에서 데이터를 주고받는 표준 규약

#! HTTP와 웹 크롤링의 관계
# : 웹 크롤링 시 웹 서버에게 정보를 요청
# : 그 응답을 받아오는 과정에서 HTTP를 사용

#! HTTP 요청과 응답
# a. 요청(request)
# : 웹 브라우저(크롤러)가 서버에게 정보나 서비스를 요청하는 메시지
# b. 응답(response)
# : 서버가 요청을 처리한 후 반환하는 메시지

#! HTTP 메서드 (동작)
# GET: 웹 페이지의 내용을 조회할 때 사용
#       , 웹 크롤링의 기본적인 요청 방식
# POST: 서버에 데이터를 보낼 때 사용

#! HTTP 상태 코드
# 200 OK - 성공적으로 응답을 받음
#  : 크롤링 대상 데이터를 가져오기 가능
# 403 Forbidden - 접근 권한이 없음
#  : 로봇 차단 정책 등으로 크롤링이 제한
# 404 Not Found - 요청한 URL에 해당하는 페이지가 없음
#  : 링크가 끊긴 페이지 참조 시 발생

### User-Agent ###
# : 웹 브라우저나 기타 클라이언트가 서버에게 자신의 신분을 알리기 위해
# : HTTP요청 헤더에 포함시키는 문자열

### robots.txt ###
# : 웹 사이트의 루트 디렉토리에 위치
# : 웹 사이트의 어느 부분을 수집 하거나
#   수집 하지 않아야 하는 지에 대한 지침을 제공
# : 민감 정보에 대한 접근 방지

# User-agent: [user-agent name]
# ex. User-agent: * (모든 크롤러에게 적용됨)

# Disallow: [URL string not to be fetched]
# ex. /private/
# : 해당 경로로 시작하는 페이지를 크롤링 하는 것을 금지
# https://www.example.com/private/

# Allow: [URL string to be fetched]
# ex. /temp/
# : 해당 경로를 포함한 하위 페이지들에 대한 크롤러 접근을 가능
